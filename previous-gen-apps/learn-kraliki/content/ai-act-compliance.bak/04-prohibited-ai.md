# Prohibited AI Systems

## Immediate Action Required

If your organization uses any of the AI systems listed below, **you must stop immediately**.

The use of prohibited AI systems is punishable by:
- **Up to â‚¬30 million in fines**
- **Or 6% of global annual revenue**
- **Immediate product recall**
- **Criminal liability for responsible individuals**

## The 8 Prohibited Categories

### 1. Subliminal Techniques

**Definition:** AI that uses subliminal techniques to materially distort a person's behavior

**What's Banned:**
- Exploiting vulnerabilities (age, disability, socioeconomic status)
- Depriving persons of informed consent
- Manipulating behavior beyond conscious awareness

**Examples:**
- AI that shows imperceptible content to influence purchases
- Vulnerability-exploiting recommendation systems
- Psychological manipulation tools

### 2. Exploitation of Vulnerabilities

**Definition:** AI that exploits specific vulnerabilities of persons or groups

**What's Banned:**
- Targeting age-related vulnerabilities (children, elderly)
- Disability exploitation
- Socioeconomic vulnerability exploitation

**Examples:**
- Predatory lending AI targeting financial distress
- AI that exploits cognitive decline in elderly users
- Scam detection tools used to find vulnerable targets

### 3. Social Scoring

**Definition:** AI that evaluates or classifies individuals based on social behavior

**What's Banned:**
- Evaluating trustworthiness based on social behavior
- Socioeconomic scoring
- Predicting likelihood of committing offenses

**Examples:**
- China-style social credit systems
- Citizen trustworthiness scoring
- Predictive policing based solely on profiling

### 4. Real-Time Biometric Identification in Public

**Definition:** AI that identifies individuals in real-time in public spaces

**What's Banned:**
- Remote biometric identification systems
- Used by law enforcement in public spaces
- Exception: Only for court-ordered investigations of serious crimes

**Examples:**
- Live facial recognition surveillance
- Real-time gait identification in public
- Crowd identification systems

### 5. Predictive Policing

**Definition:** AI that evaluates individual risk based on profiling

**What's Banned:**
- Risk assessment based solely on protected characteristics
- Ethnicity, religion, gender profiling
- Predictive policing without individual behavior evidence

**Examples:**
- Crime prediction based on neighborhood demographics
- Individual risk scores from demographic data
- Gang prediction tools using social markers

### 6. Biometric Categorization

**Definition:** AI that infers sensitive attributes from biometric data

**What's Banned:**
- Categorizing by political opinions
- Trade union membership
- Religious beliefs
- Sexual orientation
- Race or ethnicity

**Examples:**
- Political affiliation prediction from voice
- Religious classification from facial features
- Sexual orientation inference from biometrics

### 7. Emotion Recognition in Sensitive Contexts

**Definition:** AI that infers emotions in specific environments

**What's Banned:**
- **Workplaces:** Monitoring employee emotions
- **Education:** Tracking student emotional states

**Examples:**
- Employee satisfaction monitoring through facial analysis
- Student engagement tracking via emotion recognition
- Call center emotion analysis (employee side)

### 8. Untargeted Scraping of Facial Images

**Definition:** AI that scrapes facial images from internet or CCTV

**What's Banned:**
- Building facial recognition databases from web scraping
- Unclear consent collection
- Mass biometric data collection

**Examples:**
- Clearview AI-style systems
- Social media face scraping tools
- Facial database creation from public photos

## Exception Cases

### Law Enforcement Exceptions (Very Limited)

Real-time biometric identification may be used ONLY when:
1. Searching for missing children
2. Imminent threat to life or physical safety
3. Identifying suspects of serious crimes (terrorism, murder, kidnapping)
4. Court authorization obtained beforehand

### Exemptions Allowed

AI systems for:
- **National security** (military, defense)
- **Research and development** (limited, controlled environment)
- **Personal non-professional use**

## Transition Period

### Existing Systems (Before Feb 2, 2025)

If you have prohibited AI systems:
- **Immediate:** Stop using them
- **Document:** Record what was used and why
- **Decommission:** Safely remove systems and data
- **Replace:** Find compliant alternatives

### Migration Pathways

| Prohibited Use | Compliant Alternative |
|---------------|----------------------|
| Employee emotion monitoring | Anonymous surveys, feedback systems |
| Social scoring for hiring | Skills-based assessments, interviews |
| Predictive policing | Evidence-based policing, individual behavior analysis |
| Real-time face recognition | Post-hoc identification with court approval |

## Self-Assessment Checklist

For each AI system in your organization:

- [ ] Does it use subliminal techniques?
- [ ] Does it exploit user vulnerabilities?
- [ ] Does it create social scores?
- [ ] Does it use real-time biometric ID in public?
- [ ] Does it do predictive policing?
- [ ] Does it categorize by protected characteristics?
- [ ] Does it recognize emotions in workplaces/education?
- [ ] Does it scrape facial images without consent?

**If you answered YES to ANY question: STOP IMMEDIATELY**

## Immediate Actions

1. **Identify all prohibited AI** in use
2. **Document their shutdown**
3. **Notify affected users**
4. **Find compliant alternatives**
5. **Train staff** on what's not allowed

---

**Next Lesson:** High-Risk AI Requirements
